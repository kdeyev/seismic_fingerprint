{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seismic_dataset_builder  \n",
    "(X_train, y_train, v_train), (X_test, y_test, v_test), values, labels = seismic_dataset_builder.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mn (X_train, Y_train, X_test, Y_test):\n",
    "\tfrom keras.models import Model # basic class for specifying and training a neural network\n",
    "\tfrom keras.layers import Input, Dense # the two types of neural network layer we will be using\n",
    "\tfrom keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "\timport numpy as np\n",
    "\n",
    "\tprint ('image has', X_train.shape[1]*X_train.shape[2], 'pixels')\n",
    "\t\n",
    "\tbatch_size = 128 # in each iteration, we consider 128 training examples at once\n",
    "\tnum_epochs = 100 # we iterate twenty times over the entire training set\n",
    "\thidden_size = 2048 # there will be 512 neurons in both hidden layers\n",
    "\n",
    "\tnum_train = X_train.shape[0] # there are 60000 training examples in MNIST\n",
    "\tnum_test = X_test.shape[0] # there are 10000 test examples in MNIST\n",
    "\n",
    "\tin_height = X_test[0].shape[0]\n",
    "\tin_width = X_test[0].shape[1]\n",
    "\t\n",
    "\tX_train = X_train.reshape(num_train, in_height * in_width) # Flatten data to 1D\n",
    "\tX_test = X_test.reshape(num_test, in_height * in_width) # Flatten data to 1D\n",
    "\tX_train = X_train.astype('float32') \n",
    "\tX_test = X_test.astype('float32')\n",
    "\tX_train /= 255 # Normalise data to [0, 1] range\n",
    "\tX_test /= 255 # Normalise data to [0, 1] range\n",
    "\n",
    "\tout_height = Y_test[0].shape[0]\n",
    "\tout_width = Y_test[0].shape[1]\n",
    "\n",
    "\tY_train = Y_train.reshape(num_train, out_height * out_width) # Flatten data to 1D\n",
    "\tY_test = Y_test.reshape(num_test, out_height * out_width) # Flatten data to 1D\n",
    "\tY_train = Y_train.astype('float32') \n",
    "\tY_test = Y_test.astype('float32')\n",
    "\tY_train /= 255 # Normalise data to [0, 1] range\n",
    "\tY_test /= 255 # Normalise data to [0, 1] range\n",
    "\n",
    "\tinp = Input(shape=(in_height * in_width,)) # Our input is a 1D vector of size 784\n",
    "    \n",
    "\thidden = Dense(hidden_size)(inp)\n",
    "\thidden = Dense(hidden_size)(hidden)\n",
    "\thidden = Dense(hidden_size)(hidden)\n",
    "\t#hidden = Dense(hidden_size, activation='relu')(hidden)\n",
    "\t#hidden = Dense(hidden_size, activation='relu')(hidden)\n",
    "    \n",
    "\tout = Dense(out_height * out_width)(hidden) # Output softmax layer\n",
    "\n",
    "\tmodel = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "\n",
    "\tmodel.compile(loss='mean_squared_error', # using the cross-entropy loss function\n",
    "\t\t\t\t  optimizer='adadelta', # using the Adam optimiser\n",
    "\t\t\t\t  metrics=['accuracy']) # reporting the accuracy\n",
    "\n",
    "\tmodel.fit(X_train, Y_train, # Train the model using the training set...\n",
    "\t\t\t  batch_size=batch_size, nb_epoch=num_epochs,\n",
    "\t\t\t  verbose=1, validation_split=0.1) # ...holding out 10% of the data for validation\n",
    "\tprint(model.evaluate(X_test, Y_test, verbose=1)) # Evaluate the trained model on the test set!\n",
    "    \n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(76371, 37, 20, 1)\n",
      "(76371, 19, 20, 1)\n",
      "3\n",
      "(19119, 37, 20, 1)\n",
      "(19119, 19, 20, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image has 740 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kostyad\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:46: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "C:\\Users\\kostyad\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:54: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68733 samples, validate on 7638 samples\n",
      "Epoch 1/100\n",
      "68733/68733 [==============================] - 250s - loss: 0.0660 - acc: 0.0108 - val_loss: 0.0277 - val_acc: 0.0128\n",
      "Epoch 2/100\n",
      "68733/68733 [==============================] - 251s - loss: 0.0268 - acc: 0.0138 - val_loss: 0.0230 - val_acc: 0.0149\n",
      "Epoch 3/100\n",
      "68733/68733 [==============================] - 247s - loss: 0.0237 - acc: 0.0146 - val_loss: 0.0222 - val_acc: 0.0164\n",
      "Epoch 4/100\n",
      "68733/68733 [==============================] - 243s - loss: 0.0232 - acc: 0.0139 - val_loss: 0.0221 - val_acc: 0.0196\n",
      "Epoch 5/100\n",
      "68733/68733 [==============================] - 242s - loss: 0.0231 - acc: 0.0142 - val_loss: 0.0220 - val_acc: 0.0135\n",
      "Epoch 6/100\n",
      "68733/68733 [==============================] - 243s - loss: 0.0230 - acc: 0.0146 - val_loss: 0.0219 - val_acc: 0.0140\n",
      "Epoch 7/100\n",
      "68733/68733 [==============================] - 243s - loss: 0.0229 - acc: 0.0150 - val_loss: 0.0219 - val_acc: 0.0162\n",
      "Epoch 8/100\n",
      "68733/68733 [==============================] - 243s - loss: 0.0229 - acc: 0.0142 - val_loss: 0.0219 - val_acc: 0.0166\n",
      "Epoch 9/100\n",
      "68733/68733 [==============================] - 243s - loss: 0.0229 - acc: 0.0141 - val_loss: 0.0219 - val_acc: 0.0160\n",
      "Epoch 10/100\n",
      "68733/68733 [==============================] - 243s - loss: 0.0228 - acc: 0.0155 - val_loss: 0.0218 - val_acc: 0.0156\n",
      "Epoch 11/100\n",
      "68733/68733 [==============================] - 247s - loss: 0.0228 - acc: 0.0150 - val_loss: 0.0219 - val_acc: 0.0157\n",
      "Epoch 12/100\n",
      "68733/68733 [==============================] - 267s - loss: 0.0228 - acc: 0.0147 - val_loss: 0.0220 - val_acc: 0.0183\n",
      "Epoch 13/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0228 - acc: 0.0152 - val_loss: 0.0219 - val_acc: 0.0170\n",
      "Epoch 14/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0228 - acc: 0.0146 - val_loss: 0.0219 - val_acc: 0.0149\n",
      "Epoch 15/100\n",
      "68733/68733 [==============================] - 266s - loss: 0.0228 - acc: 0.0154 - val_loss: 0.0218 - val_acc: 0.0169\n",
      "Epoch 16/100\n",
      "68733/68733 [==============================] - 265s - loss: 0.0227 - acc: 0.0155 - val_loss: 0.0218 - val_acc: 0.0137\n",
      "Epoch 17/100\n",
      "68733/68733 [==============================] - 267s - loss: 0.0227 - acc: 0.0148 - val_loss: 0.0219 - val_acc: 0.0141\n",
      "Epoch 18/100\n",
      "68733/68733 [==============================] - 266s - loss: 0.0227 - acc: 0.0148 - val_loss: 0.0218 - val_acc: 0.0122\n",
      "Epoch 19/100\n",
      "68733/68733 [==============================] - 267s - loss: 0.0227 - acc: 0.0158 - val_loss: 0.0219 - val_acc: 0.0168\n",
      "Epoch 20/100\n",
      "68733/68733 [==============================] - 266s - loss: 0.0227 - acc: 0.0152 - val_loss: 0.0218 - val_acc: 0.0149\n",
      "Epoch 21/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0227 - acc: 0.0149 - val_loss: 0.0218 - val_acc: 0.0161\n",
      "Epoch 22/100\n",
      "68733/68733 [==============================] - 266s - loss: 0.0227 - acc: 0.0155 - val_loss: 0.0218 - val_acc: 0.0177\n",
      "Epoch 23/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0227 - acc: 0.0164 - val_loss: 0.0219 - val_acc: 0.0177\n",
      "Epoch 24/100\n",
      "68733/68733 [==============================] - 271s - loss: 0.0227 - acc: 0.0151 - val_loss: 0.0217 - val_acc: 0.0174\n",
      "Epoch 25/100\n",
      "68733/68733 [==============================] - 266s - loss: 0.0227 - acc: 0.0156 - val_loss: 0.0218 - val_acc: 0.0157\n",
      "Epoch 26/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0227 - acc: 0.0153 - val_loss: 0.0218 - val_acc: 0.0172\n",
      "Epoch 27/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0227 - acc: 0.0154 - val_loss: 0.0218 - val_acc: 0.0156\n",
      "Epoch 28/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0227 - acc: 0.0153 - val_loss: 0.0217 - val_acc: 0.0147\n",
      "Epoch 29/100\n",
      "68733/68733 [==============================] - 267s - loss: 0.0227 - acc: 0.0155 - val_loss: 0.0218 - val_acc: 0.0135\n",
      "Epoch 30/100\n",
      "68733/68733 [==============================] - 267s - loss: 0.0227 - acc: 0.0160 - val_loss: 0.0218 - val_acc: 0.0160\n",
      "Epoch 31/100\n",
      "68733/68733 [==============================] - 267s - loss: 0.0227 - acc: 0.0156 - val_loss: 0.0218 - val_acc: 0.0174\n",
      "Epoch 32/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0227 - acc: 0.0152 - val_loss: 0.0218 - val_acc: 0.0158\n",
      "Epoch 33/100\n",
      "68733/68733 [==============================] - 267s - loss: 0.0227 - acc: 0.0161 - val_loss: 0.0217 - val_acc: 0.0148\n",
      "Epoch 34/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0227 - acc: 0.0153 - val_loss: 0.0218 - val_acc: 0.0162\n",
      "Epoch 35/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0227 - acc: 0.0164 - val_loss: 0.0218 - val_acc: 0.0147\n",
      "Epoch 36/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0227 - acc: 0.0153 - val_loss: 0.0218 - val_acc: 0.0165\n",
      "Epoch 37/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0227 - acc: 0.0162 - val_loss: 0.0218 - val_acc: 0.0140\n",
      "Epoch 38/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0227 - acc: 0.0161 - val_loss: 0.0218 - val_acc: 0.0144\n",
      "Epoch 39/100\n",
      "68733/68733 [==============================] - 276s - loss: 0.0226 - acc: 0.0158 - val_loss: 0.0218 - val_acc: 0.0130\n",
      "Epoch 40/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0160 - val_loss: 0.0218 - val_acc: 0.0160\n",
      "Epoch 41/100\n",
      "68733/68733 [==============================] - 270s - loss: 0.0226 - acc: 0.0154 - val_loss: 0.0217 - val_acc: 0.0128\n",
      "Epoch 42/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0160 - val_loss: 0.0217 - val_acc: 0.0148\n",
      "Epoch 43/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0226 - acc: 0.0159 - val_loss: 0.0218 - val_acc: 0.0166\n",
      "Epoch 44/100\n",
      "68733/68733 [==============================] - 270s - loss: 0.0226 - acc: 0.0155 - val_loss: 0.0219 - val_acc: 0.0164\n",
      "Epoch 45/100\n",
      "68733/68733 [==============================] - 267s - loss: 0.0226 - acc: 0.0163 - val_loss: 0.0218 - val_acc: 0.0161\n",
      "Epoch 46/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0226 - acc: 0.0164 - val_loss: 0.0218 - val_acc: 0.0165\n",
      "Epoch 47/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0226 - acc: 0.0156 - val_loss: 0.0217 - val_acc: 0.0149\n",
      "Epoch 48/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0226 - acc: 0.0169 - val_loss: 0.0219 - val_acc: 0.0168\n",
      "Epoch 49/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0226 - acc: 0.0153 - val_loss: 0.0219 - val_acc: 0.0148\n",
      "Epoch 50/100\n",
      "68733/68733 [==============================] - 270s - loss: 0.0226 - acc: 0.0161 - val_loss: 0.0218 - val_acc: 0.0157\n",
      "Epoch 51/100\n",
      "68733/68733 [==============================] - 271s - loss: 0.0226 - acc: 0.0166 - val_loss: 0.0217 - val_acc: 0.0152\n",
      "Epoch 52/100\n",
      "68733/68733 [==============================] - 270s - loss: 0.0226 - acc: 0.0165 - val_loss: 0.0218 - val_acc: 0.0151\n",
      "Epoch 53/100\n",
      "68733/68733 [==============================] - 272s - loss: 0.0226 - acc: 0.0157 - val_loss: 0.0218 - val_acc: 0.0161\n",
      "Epoch 54/100\n",
      "68733/68733 [==============================] - 273s - loss: 0.0226 - acc: 0.0162 - val_loss: 0.0218 - val_acc: 0.0166\n",
      "Epoch 55/100\n",
      "68733/68733 [==============================] - 273s - loss: 0.0226 - acc: 0.0166 - val_loss: 0.0217 - val_acc: 0.0160\n",
      "Epoch 56/100\n",
      "68733/68733 [==============================] - 270s - loss: 0.0226 - acc: 0.0163 - val_loss: 0.0218 - val_acc: 0.0147\n",
      "Epoch 57/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0163 - val_loss: 0.0221 - val_acc: 0.0178\n",
      "Epoch 58/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0226 - acc: 0.0164 - val_loss: 0.0217 - val_acc: 0.0173\n",
      "Epoch 59/100\n",
      "68733/68733 [==============================] - 266s - loss: 0.0226 - acc: 0.0154 - val_loss: 0.0218 - val_acc: 0.0158\n",
      "Epoch 60/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0226 - acc: 0.0168 - val_loss: 0.0217 - val_acc: 0.0156\n",
      "Epoch 61/100\n",
      "68733/68733 [==============================] - 270s - loss: 0.0226 - acc: 0.0153 - val_loss: 0.0217 - val_acc: 0.0166\n",
      "Epoch 62/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0159 - val_loss: 0.0218 - val_acc: 0.0152\n",
      "Epoch 63/100\n",
      "68733/68733 [==============================] - 267s - loss: 0.0226 - acc: 0.0168 - val_loss: 0.0217 - val_acc: 0.0154\n",
      "Epoch 64/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0152 - val_loss: 0.0217 - val_acc: 0.0162\n",
      "Epoch 65/100\n",
      "68733/68733 [==============================] - 270s - loss: 0.0226 - acc: 0.0166 - val_loss: 0.0218 - val_acc: 0.0185\n",
      "Epoch 66/100\n",
      "68733/68733 [==============================] - 270s - loss: 0.0226 - acc: 0.0170 - val_loss: 0.0218 - val_acc: 0.0196\n",
      "Epoch 67/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0226 - acc: 0.0162 - val_loss: 0.0218 - val_acc: 0.0175\n",
      "Epoch 68/100\n",
      "68733/68733 [==============================] - 267s - loss: 0.0226 - acc: 0.0165 - val_loss: 0.0217 - val_acc: 0.0149\n",
      "Epoch 69/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0226 - acc: 0.0167 - val_loss: 0.0217 - val_acc: 0.0147\n",
      "Epoch 70/100\n",
      "68733/68733 [==============================] - 270s - loss: 0.0226 - acc: 0.0161 - val_loss: 0.0218 - val_acc: 0.0118\n",
      "Epoch 71/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0168 - val_loss: 0.0217 - val_acc: 0.0151\n",
      "Epoch 72/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0158 - val_loss: 0.0218 - val_acc: 0.0135\n",
      "Epoch 73/100\n",
      "68733/68733 [==============================] - 270s - loss: 0.0226 - acc: 0.0165 - val_loss: 0.0219 - val_acc: 0.0132\n",
      "Epoch 74/100\n",
      "68733/68733 [==============================] - 272s - loss: 0.0226 - acc: 0.0169 - val_loss: 0.0218 - val_acc: 0.0169\n",
      "Epoch 75/100\n",
      "68733/68733 [==============================] - 273s - loss: 0.0226 - acc: 0.0162 - val_loss: 0.0218 - val_acc: 0.0149\n",
      "Epoch 76/100\n",
      "68733/68733 [==============================] - 270s - loss: 0.0226 - acc: 0.0166 - val_loss: 0.0219 - val_acc: 0.0143\n",
      "Epoch 77/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0164 - val_loss: 0.0219 - val_acc: 0.0144\n",
      "Epoch 78/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0156 - val_loss: 0.0217 - val_acc: 0.0139\n",
      "Epoch 79/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0163 - val_loss: 0.0217 - val_acc: 0.0151\n",
      "Epoch 80/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0164 - val_loss: 0.0217 - val_acc: 0.0141\n",
      "Epoch 81/100\n",
      "68733/68733 [==============================] - 270s - loss: 0.0226 - acc: 0.0160 - val_loss: 0.0218 - val_acc: 0.0161\n",
      "Epoch 82/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0169 - val_loss: 0.0217 - val_acc: 0.0151\n",
      "Epoch 83/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0164 - val_loss: 0.0220 - val_acc: 0.0117\n",
      "Epoch 84/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0163 - val_loss: 0.0217 - val_acc: 0.0128\n",
      "Epoch 85/100\n",
      "68733/68733 [==============================] - 270s - loss: 0.0226 - acc: 0.0159 - val_loss: 0.0217 - val_acc: 0.0131\n",
      "Epoch 86/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0226 - acc: 0.0159 - val_loss: 0.0217 - val_acc: 0.0131\n",
      "Epoch 87/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0226 - acc: 0.0172 - val_loss: 0.0219 - val_acc: 0.0149\n",
      "Epoch 88/100\n",
      "68733/68733 [==============================] - 268s - loss: 0.0226 - acc: 0.0160 - val_loss: 0.0218 - val_acc: 0.0130\n",
      "Epoch 89/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0168 - val_loss: 0.0218 - val_acc: 0.0156\n",
      "Epoch 90/100\n",
      "68733/68733 [==============================] - 270s - loss: 0.0226 - acc: 0.0168 - val_loss: 0.0218 - val_acc: 0.0151\n",
      "Epoch 91/100\n",
      "68733/68733 [==============================] - 269s - loss: 0.0226 - acc: 0.0155 - val_loss: 0.0217 - val_acc: 0.0157\n",
      "Epoch 92/100\n",
      "68733/68733 [==============================] - 270s - loss: 0.0226 - acc: 0.0155 - val_loss: 0.0217 - val_acc: 0.0149\n",
      "Epoch 93/100\n",
      "68733/68733 [==============================] - 254s - loss: 0.0226 - acc: 0.0168 - val_loss: 0.0219 - val_acc: 0.0170\n",
      "Epoch 94/100\n",
      "68733/68733 [==============================] - 253s - loss: 0.0226 - acc: 0.0160 - val_loss: 0.0217 - val_acc: 0.0144\n",
      "Epoch 95/100\n",
      "68733/68733 [==============================] - 250s - loss: 0.0226 - acc: 0.0161 - val_loss: 0.0217 - val_acc: 0.0161\n",
      "Epoch 96/100\n",
      "68733/68733 [==============================] - 246s - loss: 0.0226 - acc: 0.0166 - val_loss: 0.0217 - val_acc: 0.0147\n",
      "Epoch 97/100\n",
      "68733/68733 [==============================] - 247s - loss: 0.0226 - acc: 0.0160 - val_loss: 0.0219 - val_acc: 0.0162\n",
      "Epoch 98/100\n",
      "68733/68733 [==============================] - 247s - loss: 0.0226 - acc: 0.0159 - val_loss: 0.0218 - val_acc: 0.0144\n",
      "Epoch 99/100\n",
      "68733/68733 [==============================] - 246s - loss: 0.0226 - acc: 0.0163 - val_loss: 0.0218 - val_acc: 0.0123\n",
      "Epoch 100/100\n",
      "68733/68733 [==============================] - 43272s - loss: 0.0226 - acc: 0.0175 - val_loss: 0.0217 - val_acc: 0.0177\n",
      "19104/19119 [============================>.] - ETA: 0s[0.022527089942118272, 0.015325069302787802]\n"
     ]
    }
   ],
   "source": [
    "print (len(X_train))\n",
    "\n",
    "print (X_train[0].shape)\n",
    "print (X_train[1].shape)\n",
    "\n",
    "print (len(X_test))\n",
    "print (X_test[0].shape)\n",
    "print (X_test[1].shape)\n",
    "\n",
    "model = mn(X_train[0], X_train[2], X_test[0], X_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mn_evaluate_random(model, X_test, Y_test):\n",
    "\timport numpy as np\n",
    "\t\t\n",
    "\tdef slice (X_test, num):\n",
    "\t\tsingle = []\n",
    "\t\tfor i in range(len(X_test)):\n",
    "\t\t\tsingle.append(np.array([X_test[i][num]]))\n",
    "\t\treturn single\n",
    "\t\n",
    "\trandidx = np.random.randint(0, len(X_test))\n",
    "\tx = np.array([X_test[randidx]])\n",
    "\ty = np.array([Y_test[randidx]])\n",
    "    \n",
    "\ty_height = Y_test[0].shape[0]\n",
    "\ty_width = Y_test[0].shape[1]\n",
    "\tx_height = X_test[0].shape[0]\n",
    "\tx_width = X_test[0].shape[1]\n",
    "\t\n",
    "\t#x = x.reshape(x_height * x_width) # Flatten data to 1D\n",
    "\tx = x.astype('float32') \n",
    "\tx /= 255 # Normalise data to [0, 1] range\n",
    "\n",
    "\t#y = y.reshape(y_height * y_width) # Flatten data to 1D\n",
    "\ty = y.astype('float32') \n",
    "\ty /= 255 # Normalise data to [0, 1] range\n",
    "\t\n",
    "\tfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "\timport matplotlib.pyplot as plt\n",
    "\tfig = plt.figure(figsize=(16, 4))\n",
    "\n",
    "\ta = x[0] \n",
    "\ta = a.T[0].T\n",
    "\tax = fig.add_subplot(131)\n",
    "\tvm = np.percentile(a, 99)\n",
    "\timparams = {\n",
    "\t\t#'interpolation': 'none',\n",
    "\t\t'cmap': \"gray\",\n",
    "\t\t'vmin': -vm,\n",
    "\t\t'vmax': vm,\n",
    "\t\t'aspect': 'auto'\n",
    "\t}\n",
    "\tplt.imshow(a, **imparams)\n",
    "\n",
    "\ta = y[0] \n",
    "\ta = a.T[0].T\n",
    "\n",
    "\tax = fig.add_subplot(132)\n",
    "\n",
    "\timparams = {\n",
    "\t\t#'interpolation': 'none',\n",
    "\t\t'cmap': \"gray\",\n",
    "\t\t'aspect': 'auto'\n",
    "\t\t}\n",
    "\tplt.imshow(a, **imparams)\n",
    "\n",
    "\tX = X_test[randidx]\n",
    "\tX = X.reshape(1, x_height * x_width) # Flatten data to 1D\n",
    "\tX = X.astype('float32')\n",
    "\tX /= 255 # Normalise data to [0, 1] range\n",
    "\t\n",
    "\tpredicted_y = model.predict(X)\n",
    "    \n",
    "\tpredicted_y = predicted_y.reshape(y_height, y_width)\n",
    "\ta = predicted_y\n",
    "\t\n",
    "\t#a = a.T[0].T\n",
    "\tax = fig.add_subplot(133)\n",
    "\n",
    "\timparams = {\n",
    "\t\t#'interpolation': 'none',\n",
    "\t\t'cmap': \"gray\",\n",
    "\t\t'aspect': 'auto'\n",
    "\t\t}\n",
    "\tplt.imshow(a, **imparams)\n",
    "\n",
    "\treturn randidx, x, y, predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6IAAAD8CAYAAABtlBmdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f2cd82a5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "randidx, x, y, predicted_y = mn_evaluate_random(model, X_test[0], X_test[2])\n",
    "#print (y)\n",
    "#print (predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

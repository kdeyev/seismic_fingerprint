{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import seismic_dataset_builder  \n",
    "(X_train, y_train, v_train), (X_test, y_test, v_test), values, labels = seismic_dataset_builder.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mn (X_train, Y_train, X_test, Y_test):\n",
    "\tfrom keras.models import Model # basic class for specifying and training a neural network\n",
    "\tfrom keras.layers import Input, Dense # the two types of neural network layer we will be using\n",
    "\tfrom keras.utils import np_utils # utilities for one-hot encoding of ground truth values\n",
    "\timport numpy as np\n",
    "\n",
    "\tprint ('image has', X_train.shape[1]*X_train.shape[2], 'pixels')\n",
    "\t\n",
    "\tbatch_size = 128 # in each iteration, we consider 128 training examples at once\n",
    "\tnum_epochs = 20 # we iterate twenty times over the entire training set\n",
    "\thidden_size = 1025 # there will be 512 neurons in both hidden layers\n",
    "\n",
    "\tnum_train = X_train.shape[0] # there are 60000 training examples in MNIST\n",
    "\tnum_test = X_test.shape[0] # there are 10000 test examples in MNIST\n",
    "\n",
    "\tin_height = X_test[0].shape[0]\n",
    "\tin_width = X_test[0].shape[1]\n",
    "\t\n",
    "\tX_train = X_train.reshape(num_train, in_height * in_width) # Flatten data to 1D\n",
    "\tX_test = X_test.reshape(num_test, in_height * in_width) # Flatten data to 1D\n",
    "\tX_train = X_train.astype('float32') \n",
    "\tX_test = X_test.astype('float32')\n",
    "\tX_train /= 255 # Normalise data to [0, 1] range\n",
    "\tX_test /= 255 # Normalise data to [0, 1] range\n",
    "\n",
    "\tout_height = Y_test[0].shape[0]\n",
    "\tout_width = Y_test[0].shape[1]\n",
    "\n",
    "\tY_train = Y_train.reshape(num_train, out_height * out_width) # Flatten data to 1D\n",
    "\tY_test = Y_test.reshape(num_test, out_height * out_width) # Flatten data to 1D\n",
    "\tY_train = Y_train.astype('float32') \n",
    "\tY_test = Y_test.astype('float32')\n",
    "\tY_train /= 255 # Normalise data to [0, 1] range\n",
    "\tY_test /= 255 # Normalise data to [0, 1] range\n",
    "\n",
    "\tinp = Input(shape=(in_height * in_width,)) # Our input is a 1D vector of size 784\n",
    "    \n",
    "\thidden = Dense(hidden_size)(inp)\n",
    "\thidden = Dense(hidden_size, activation='relu')(hidden) # Second hidden ReLU layer\n",
    "\t#hidden = Dense(hidden_size, activation='relu')(hidden) # Second hidden ReLU layer\n",
    "\t#hidden = Dense(hidden_size, activation='relu')(hidden) # Second hidden ReLU layer\n",
    "    \n",
    "\tout = Dense(out_height * out_width)(hidden) # Output softmax layer\n",
    "\n",
    "\tmodel = Model(input=inp, output=out) # To define a model, just specify its input and output layers\n",
    "\n",
    "\tmodel.compile(loss='mean_squared_error', # using the cross-entropy loss function\n",
    "\t\t\t\t  optimizer='adadelta', # using the Adam optimiser\n",
    "\t\t\t\t  metrics=['accuracy']) # reporting the accuracy\n",
    "\n",
    "\tmodel.fit(X_train, Y_train, # Train the model using the training set...\n",
    "\t\t\t  batch_size=batch_size, nb_epoch=num_epochs,\n",
    "\t\t\t  verbose=1, validation_split=0.1) # ...holding out 10% of the data for validation\n",
    "\tprint(model.evaluate(X_test, Y_test, verbose=1)) # Evaluate the trained model on the test set!\n",
    "    \n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-c84299465827>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print (len(X_train))\n",
    "\n",
    "print (X_train[0].shape)\n",
    "print (X_train[1].shape)\n",
    "\n",
    "print (len(X_test))\n",
    "print (X_test[0].shape)\n",
    "print (X_test[1].shape)\n",
    "\n",
    "model = mn(X_train[0], X_train[2], X_test[0], X_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mn_evaluate_random(model, X_test, Y_test):\n",
    "\timport numpy as np\n",
    "\t\t\n",
    "\tdef slice (X_test, num):\n",
    "\t\tsingle = []\n",
    "\t\tfor i in range(len(X_test)):\n",
    "\t\t\tsingle.append(np.array([X_test[i][num]]))\n",
    "\t\treturn single\n",
    "\t\n",
    "\trandidx = np.random.randint(0, len(X_test))\n",
    "\tx = np.array([X_test[randidx]])\n",
    "\ty = np.array([Y_test[randidx]])\n",
    "    \n",
    "\ty_height = Y_test[0].shape[0]\n",
    "\ty_width = Y_test[0].shape[1]\n",
    "\tx_height = X_test[0].shape[0]\n",
    "\tx_width = X_test[0].shape[1]\n",
    "\t\n",
    "\t#x = x.reshape(x_height * x_width) # Flatten data to 1D\n",
    "\tx = x.astype('float32') \n",
    "\tx /= 255 # Normalise data to [0, 1] range\n",
    "\n",
    "\t#y = y.reshape(y_height * y_width) # Flatten data to 1D\n",
    "\ty = y.astype('float32') \n",
    "\ty /= 255 # Normalise data to [0, 1] range\n",
    "\t\n",
    "\tfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "\timport matplotlib.pyplot as plt\n",
    "\tfig = plt.figure(figsize=(16, 4))\n",
    "\n",
    "\ta = x[0] \n",
    "\ta = a.T[0].T\n",
    "\tax = fig.add_subplot(131)\n",
    "\tvm = np.percentile(a, 99)\n",
    "\timparams = {\n",
    "\t\t#'interpolation': 'none',\n",
    "\t\t'cmap': \"gray\",\n",
    "\t\t'vmin': -vm,\n",
    "\t\t'vmax': vm,\n",
    "\t\t'aspect': 'auto'\n",
    "\t}\n",
    "\tplt.imshow(a, **imparams)\n",
    "\n",
    "\ta = y[0] \n",
    "\ta = a.T[0].T\n",
    "\n",
    "\tax = fig.add_subplot(132)\n",
    "\n",
    "\timparams = {\n",
    "\t\t#'interpolation': 'none',\n",
    "\t\t'cmap': \"gray\",\n",
    "\t\t'aspect': 'auto'\n",
    "\t\t}\n",
    "\tplt.imshow(a, **imparams)\n",
    "\n",
    "\tX = X_test[randidx]\n",
    "\tX = X.reshape(1, x_height * x_width) # Flatten data to 1D\n",
    "\tX = X.astype('float32')\n",
    "\tX /= 255 # Normalise data to [0, 1] range\n",
    "\t\n",
    "\tpredicted_y = model.predict(X)\n",
    "    \n",
    "\tpredicted_y = predicted_y.reshape(y_height, y_width)\n",
    "\ta = predicted_y\n",
    "\t\n",
    "\t#a = a.T[0].T\n",
    "\tax = fig.add_subplot(133)\n",
    "\n",
    "\timparams = {\n",
    "\t\t#'interpolation': 'none',\n",
    "\t\t'cmap': \"gray\",\n",
    "\t\t'aspect': 'auto'\n",
    "\t\t}\n",
    "\tplt.imshow(a, **imparams)\n",
    "\n",
    "\treturn randidx, x, y, predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "randidx, x, y, predicted_y = mn_evaluate_random(model, X_test[0], X_test[2])\n",
    "#print (y)\n",
    "print (predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

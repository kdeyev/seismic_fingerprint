{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# run TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "python -m tensorflow.tensorboard --logdir=outputs/Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "layer_name_dict = {\n",
    "    'Dense': 'denseLayer',\n",
    "    'Dropout': 'dropoutLayer',\n",
    "    'Flatten': 'flattenLayer',\n",
    "    'Embedding': 'embeddingLayer',\n",
    "    'BatchNormalization': 'batchNormalizationLayer',\n",
    "    'LeakyReLU': 'leakyReLULayer',\n",
    "    'PReLU': 'parametricReLULayer',\n",
    "    'ParametricSoftplus': 'parametricSoftplusLayer',\n",
    "    'ThresholdedLinear': 'thresholdedLinearLayer',\n",
    "    'ThresholdedReLu': 'thresholdedReLuLayer',\n",
    "    'LSTM': 'rLSTMLayer',\n",
    "    'GRU': 'rGRULayer',\n",
    "    'JZS1': 'rJZS1Layer',\n",
    "    'JZS2': 'rJZS2Layer',\n",
    "    'JZS3': 'rJZS3Layer',\n",
    "    'Convolution2D': 'convolution2DLayer',\n",
    "    'MaxPooling2D': 'maxPooling2DLayer'\n",
    "}\n",
    "\n",
    "layer_params_dict = {\n",
    "    'Dense': ['weights', 'activation'],\n",
    "    'Dropout': ['p'],\n",
    "    'Flatten': [],\n",
    "    'Embedding': ['weights'],\n",
    "    'BatchNormalization': ['weights', 'epsilon'],\n",
    "    'LeakyReLU': ['alpha'],\n",
    "    'PReLU': ['weights'],\n",
    "    'ParametricSoftplus': ['weights'],\n",
    "    'ThresholdedLinear': ['theta'],\n",
    "    'ThresholdedReLu': ['theta'],\n",
    "    'LSTM': ['weights', 'activation', 'inner_activation', 'return_sequences'],\n",
    "    'GRU': ['weights', 'activation', 'inner_activation', 'return_sequences'],\n",
    "    'JZS1': ['weights', 'activation', 'inner_activation', 'return_sequences'],\n",
    "    'JZS2': ['weights', 'activation', 'inner_activation', 'return_sequences'],\n",
    "    'JZS3': ['weights', 'activation', 'inner_activation', 'return_sequences'],\n",
    "    'Convolution2D': ['weights', 'nb_filter', 'nb_row', 'nb_col', 'border_mode', 'subsample', 'activation'],\n",
    "    'MaxPooling2D': ['pool_size', 'stride', 'ignore_border']\n",
    "}\n",
    "\n",
    "layer_weights_dict = {\n",
    "    'Dense': ['W', 'b'],\n",
    "    'Embedding': ['E'],\n",
    "    'BatchNormalization': ['gamma', 'beta', 'mean', 'std'],\n",
    "    'PReLU': ['alphas'],\n",
    "    'ParametricSoftplus': ['alphas', 'betas'],\n",
    "    'LSTM': ['W_xi', 'W_hi', 'b_i', 'W_xc', 'W_hc', 'b_c', 'W_xf', 'W_hf', 'b_f', 'W_xo', 'W_ho', 'b_o'],\n",
    "    'GRU': ['W_xz', 'W_hz', 'b_z', 'W_xr', 'W_hr', 'b_r', 'W_xh', 'W_hh', 'b_h'],\n",
    "    'JZS1': ['W_xz', 'b_z', 'W_xr', 'W_hr', 'b_r', 'W_hh', 'b_h', 'Pmat'],\n",
    "    'JZS2': ['W_xz', 'W_hz', 'b_z', 'W_hr', 'b_r', 'W_xh', 'W_hh', 'b_h', 'Pmat'],\n",
    "    'JZS3': ['W_xz', 'W_hz', 'b_z', 'W_xr', 'W_hr', 'b_r', 'W_xh', 'W_hh', 'b_h'],\n",
    "    'Convolution2D': ['W', 'b']\n",
    "}\n",
    "\n",
    "def serialize(model_json_file, weights_hdf5_file, save_filepath, compress):\n",
    "    with open(model_json_file, 'r') as f:\n",
    "        model_metadata = json.load(f)\n",
    "    weights_file = h5py.File(weights_hdf5_file, 'r')\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    num_activation_layers = 0\n",
    "    for k, layer in enumerate(model_metadata['layers']):\n",
    "        if layer['name'] == 'Activation':\n",
    "            num_activation_layers += 1\n",
    "            prev_layer_name = model_metadata['layers'][k-1]['name']\n",
    "            idx_activation = layer_params_dict[prev_layer_name].index('activation')\n",
    "            layers[k-num_activation_layers]['parameters'][idx_activation] = layer['activation']\n",
    "            continue\n",
    "\n",
    "        layer_params = []\n",
    "\n",
    "        for param in layer_params_dict[layer['name']]:\n",
    "            if param == 'weights':\n",
    "                layer_weights = list(weights_file.get('layer_{}'.format(k)))\n",
    "                weights = {}\n",
    "                weight_names = layer_weights_dict[layer['name']]\n",
    "                for name, w in zip(weight_names, layer_weights):\n",
    "                    weights[name] = weights_file.get('layer_{}/{}'.format(k, w)).value.tolist()\n",
    "                layer_params.append(weights)\n",
    "            else:\n",
    "                layer_params.append(layer[param])\n",
    "\n",
    "        layers.append({\n",
    "            'layerName': layer_name_dict[layer['name']],\n",
    "            'parameters': layer_params\n",
    "        })\n",
    "\n",
    "    if compress:\n",
    "        with gzip.open(save_filepath, 'wb') as f:\n",
    "            f.write(json.dumps(layers).encode('utf8'))\n",
    "    else:\n",
    "        with open(save_filepath, 'w') as f:\n",
    "            json.dump(layers, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "model_metadata = json.loads(model.to_json())\n",
    "\n",
    "with open('web_interface/model.json', 'w') as f:\n",
    "    json.dump(model_metadata, f)\n",
    "    \n",
    "model.save_weights('web_interface/weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "serialize('web_interface/model.json', \n",
    "          'web_interface/model.hdf5', \n",
    "          'web_interface/model_params.json.gz', \n",
    "          True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_save = [a.tolist() for a in X_test]\n",
    "with gzip.open('web_interface/data.json.gz', 'wb') as f:\n",
    "    f.write(json.dumps({'data': X_save, 'labels': y_test.tolist()}).encode('utf8'))\n",
    "#with open('sample_data.json', 'w') as f:\n",
    "#    json.dump({'data': X_rand.tolist(), 'labels': y_rand.tolist()}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import encoder\n",
    "e = Encoder ('web_interface/model.hdf5')\n",
    "e.serialize()\n",
    "e.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
